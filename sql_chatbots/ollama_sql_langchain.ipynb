{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "LANGCHAIN_API_KEY = os.getenv(key=\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_ENDPOINT = os.getenv(key=\"LANGCHAIN_ENDPOINT\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(key=\"LANGCHAIN_TRACING_V2\")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.pydantic_v1 import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_llm = ChatOllama(model='phi',temperature=0.1,timeout=300)\n",
    "gemma_llm = ChatOllama(model='gemma:2b',temperature=0.1,timeout=300)\n",
    "llm = phi_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB: Connect to a SQLite DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///nba_roster.db\", sample_rows_in_table_info= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Golden State Warriors',)]\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the db\n",
    "query = \"SELECT Team FROM nba_roster WHERE NAME = 'Klay Thompson'\"\n",
    "db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(30,)]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT COUNT(DISTINCT Team) FROM nba_roster\"\n",
    "db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompts and templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"Based on the table schema below, return a SQL query that would answer the user's question:\n",
    "# {schema}\n",
    "\n",
    "# Question: {question}\n",
    "# SQL Query: \"\"\"  # noqa: E501\n",
    "\n",
    "template = \"\"\"Based on the table schema below, return only a SQL query that would answer the user's question. No pre-amble.:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"  # noqa: E501\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Given an input question, convert it to a SQL query. No pre-amble.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['history', 'question', 'schema'] input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given an input question, convert it to a SQL query. No pre-amble.')), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'schema'], template=\"Based on the table schema below, return only a SQL query that would answer the user's question. No pre-amble.:\\n{schema}\\n\\nQuestion: {question}\\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain to query with memory\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        history=RunnableLambda(lambda x: memory.load_memory_variables(x)[\"history\"]),\n",
    "    )\n",
    "    | prompt\n",
    "    # | llm.bind(stop=[\"\\nUser:\"])\n",
    "    | llm.bind(stop=[\"\\n\"])\n",
    "    # | llm.bind(stop=[\"\\nUser:\", \"\\nRules:\", \"\\nAssistant\"])\n",
    "    # | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(input_output):\n",
    "    output = {\"output\": input_output.pop(\"output\")}\n",
    "    memory.save_context(input_output, output)\n",
    "    return output[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_response_memory = RunnablePassthrough.assign(output=sql_chain) | save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain to answer\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"  # noqa: E501\n",
    "\n",
    "prompt_response = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and SQL response, convert it to a natural \"\n",
    "            \"language answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", template),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query', 'question', 'response', 'schema'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Given an input question and SQL response, convert it to a natural language answer. No pre-amble.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query', 'question', 'response', 'schema'], template='Based on the table schema below, question, sql query, and sql response, write a natural language response:\\n{schema}\\n\\nQuestion: {question}\\nSQL Query: {query}\\nSQL Response: {response}'))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply the input types to the prompt\n",
    "class InputType(BaseModel):\n",
    "    question: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response_memory).with_types(\n",
    "        input_type=InputType\n",
    "    )\n",
    "    | RunnablePassthrough.assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' According to the table schema and SQL query, Klay Thompson is currently on the Golden State Warriors.\\n', response_metadata={'model': 'phi', 'created_at': '2024-04-24T10:19:06.2046974Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 4642295400, 'load_duration': 16183000, 'prompt_eval_count': 180, 'prompt_eval_duration': 3948213000, 'eval_count': 23, 'eval_duration': 671977000}, id='run-da0fab95-af66-44b0-8002-b0f642fa755c-0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What team is Klay Thompson on?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' There are 17 players on the Golden State Warriors team.\\n', response_metadata={'model': 'phi', 'created_at': '2024-04-24T10:11:55.8484957Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 4315582200, 'load_duration': 2527400, 'prompt_eval_count': 185, 'prompt_eval_duration': 3909099000, 'eval_count': 14, 'eval_duration': 398412000}, id='run-93adcde8-c125-473a-a519-37efe82eddbb-0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"Give me total number of players in Golden State Warriors Team?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' There is only one team in the database.\\n', response_metadata={'model': 'phi', 'created_at': '2024-04-24T10:24:02.1316283Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 4362815900, 'load_duration': 6025900, 'prompt_eval_count': 180, 'prompt_eval_duration': 4022880000, 'eval_count': 12, 'eval_duration': 326051000}, id='run-6d09221a-ea6d-47fa-b551-448707343d5f-0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"How many total different teams are there in database?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
