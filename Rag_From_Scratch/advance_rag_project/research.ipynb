{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "LANGCHAIN_API_KEY = os.getenv(key=\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_ENDPOINT = os.getenv(key=\"LANGCHAIN_ENDPOINT\")\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(key=\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_PROJECT = os.getenv(key=\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import streamlit as st\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from langchain.llms.ollama import Ollama\n",
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data ingestion\n",
    "def data_ingestion():\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "        bs_kwargs=dict(\n",
    "            parse_only=bs4.SoupStrainer(\n",
    "                class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    # Split Data\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(documents=docs)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_llm():\n",
    "    llm = Ollama(model=\"phi\", temperature=0, timeout=300)\n",
    "    return llm\n",
    "\n",
    "\n",
    "def gemma_llm():\n",
    "    llm = Ollama(model=\"gemma\", temperature=0, timeout=300)\n",
    "    return llm\n",
    "\n",
    "\n",
    "def embed_llm():\n",
    "    llm = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a vector store\n",
    "def create_vector_store(doc):\n",
    "    vectordb = Chroma.from_documents(documents=doc, embedding=embed_llm(), persist_directory=\"chroma_index\")\n",
    "    vectordb.persist()\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever():\n",
    "    vectorstore = Chroma(persist_directory=\"chroma_index\", embedding_function=embed_llm())\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(llm, retriever, query):\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "    )\n",
    "    answer = rag_chain.invoke({\"query\": query})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data_ingestion()\n",
    "vectordb = create_vector_store(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = phi_llm()\n",
    "retriever = create_retriever()\n",
    "user_question = \"What is Langchain?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = get_llm_response(llm, retriever, user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.vectorstores import Weaviate\n",
    "# import weaviate\n",
    "\n",
    "# docs = data_ingestion()\n",
    "# vectordb = Weaviate.from_documents(documents=docs, embedding=embed_llm())\n",
    "\n",
    "# from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "# client = weaviate.Client(embedded_options=embed_llm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  SystemMessage(\n",
    "   content=\"\"\"You're an assistant knowledgeable about\n",
    "   healthcare. Only answer healthcare-related questions.\"\"\"\n",
    "  ),\n",
    "  HumanMessage(content=\"What is Medicaid managed care?\"),\n",
    " ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
