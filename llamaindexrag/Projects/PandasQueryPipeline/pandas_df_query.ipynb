{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "px.close_app()\n",
    "# px.launch_app()\n",
    "# import llama_index.core\n",
    "# llama_index.core.set_global_handler(\"arize_phoenix\")\n",
    "# print(px.active_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent\n",
    ")\n",
    "from llama_index.core.query_engine.pandas import PandasInstructionParser\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/docs/examples/data/csv/titanic_train.csv' -O 'titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"D:\\Gen_AI_Tutorials\\langchain\\llamaindexrag\\csv_data\\titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    # that can be called with the `eval()` function.\n",
    "    \"2. The final line of code should be a Python expression.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str = instruction_str,\n",
    "    df_str=df.head(5)\n",
    ")\n",
    "\n",
    "pandas_output_parser = PandasInstructionParser(df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding Model\n",
    "embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "# llm\n",
    "llm= Ollama(model=\"phi\",request_timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\":InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links([\n",
    "    Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "    Link(\"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"),\n",
    "    Link(\"pandas_output_parser\", \"response_synthesis_prompt\", dest_key=\"pandas_output\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add link from response synthesis prompt to llm2\n",
    "qp.add_link(\"response_synthesis_prompt\", \"llm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create graph\n",
    "# from pyvis.network import Network\n",
    "\n",
    "# net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "# net.from_nx(qp.dag)\n",
    "# net.show(\"panda_query_rag.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: What is the correlation between survival and age?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: What is the correlation between survival and age?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "   survived  pclass  ... cabin embarked\n",
      "0         0       3  ...   NaN  ...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant:  A possible answer is:\n",
      "\n",
      "# Convert the query to executable Python code using pandas\n",
      "import pandas as pd\n",
      "df = pd.read_csv('titanic.csv') # load the dataframe from a CSV file\n",
      "correlation = df[...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: What is the correlation between survival and age?\n",
      "pandas_instructions: assistant:  A possible answer is:\n",
      "\n",
      "# Convert the query to executable Python code using pandas\n",
      "import pandas as pd\n",
      "df = pd.read_csv('titanic.csv') # load the dataframe from a CSV file\n",
      "correlation = df[...\n",
      "pandas_output: There was an error running the output as Python code. Error message: invalid syntax (<unknown>, line 1)\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: What is the correlation between survival and age?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      " A possible answer is:\n",
      "\n",
      "# Convert the q...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\Gen_AI_Tutorials\\langchain\\venv\\lib\\site-packages\\llama_index\\core\\query_engine\\pandas\\output_parser.py\", line 40, in default_output_processor\n",
      "    tree = ast.parse(output)\n",
      "  File \"d:\\Gen_AI_Tutorials\\langchain\\venv\\lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "  File \"<unknown>\", line 1\n",
      "    A possible answer is:\n",
      "      ^^^^^^^^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = qp.run(\n",
    "    query_str=\"What is the correlation between survival and age?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I apologize for the error in executing the Pandas instructions. Let me try to answer your question using other methods. The correlation between survival and age is 0.058, which means that there is a weak positive relationship between the two variables. This suggests that older individuals are more likely to survive, but the effect is not very strong.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
